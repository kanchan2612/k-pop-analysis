{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=log['key'][0]\n",
    "consumer_secret=log['key'][1]\n",
    "access_token=log['key'][2]\n",
    "access_secret_token=log['key'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring the variable for authorization \n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_secret_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittes= api.home_timeline() #gets the live timeline updates of your account.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tweet in twittes:  \n",
    "    print(tweet.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the tweets stream and sentiment analysis it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #importing the necessary libraries \n",
    "from tweepy import Stream                   #for the continues streams on twitter\n",
    "from tweepy import StreamListener \n",
    "import json\n",
    "from textblob import TextBlob            #for the sentiment analysis\n",
    "\n",
    "import re\n",
    "import csv             #for wirting the csv file for the tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the variables for tracking the sentiments\n",
    "bts=0  \n",
    "blackpink=0\n",
    "header_name=['BTS','BLACKPINK']          #creating the csv file\n",
    "with open('sentiment.csv','w') as file:\n",
    "    writer = csv.DictWriter(file,fieldnames=header_name)\n",
    "    writer.writeheader()\n",
    "\n",
    "class Listner(StreamListener):    \n",
    "    def on_data(self,data):            #receive the data from streamlistener\n",
    "        raw_twitts =json.loads(data)    \n",
    "        try:\n",
    "            tweets = raw_twitts['text']  \n",
    "            #filtering the tweets by using 2 regular expresssion which remove '@' and 'RT' to get the clean tweets\n",
    "            tweets = ' '.join(re.sub(\"(@ [A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \",tweets).split())\n",
    "            tweets = ' '.join(re.sub('RT',' ',tweets).split())\n",
    "            \n",
    "            blob = TextBlob(tweets.strip()) #accessing the sentiments\n",
    "            \n",
    "            global bts            \n",
    "            global blackpink\n",
    "            \n",
    "            bts_sentiment =0        \n",
    "            blackpink_sentiment=0\n",
    "            \n",
    "            \n",
    "            for sent in blob.sentences:\n",
    "                if \"BTS\" in sent and  \"BLACKPINK\" not in sent:\n",
    "                    bts_sentiment = bts_sentiment + sent.sentiment.polarity\n",
    "                else:\n",
    "                    blackpink_sentiment = blackpink_sentiment + sent.sentiment.polarity\n",
    "                    \n",
    "                bts = bts + bts_sentiment\n",
    "                blackpink = blackpink + blackpink_sentiment\n",
    "                \n",
    "                with open('sentiment.csv','a') as file:          #appending the data in csv file\n",
    "                    writer = csv.DictWriter(file, fieldnames=header_name)\n",
    "                    info = {\n",
    "                        'BTS': bts,\n",
    "                        'BLACKPINK': blackpink\n",
    "                    }\n",
    "                    writer.writerow(info)\n",
    "                \n",
    "            \n",
    "            print(tweets)\n",
    "            \n",
    "            print()\n",
    "        except:\n",
    "            print('error got')\n",
    "    def on_error(self,status):   # recives the status\n",
    "        print(status)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_secret_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a twitter stream which takes the authorisation and then ask about the listner \n",
    "twitter_stream = Stream(auth, Listner())\n",
    "twitter_stream.filter(track =['BTS','BLACKPINK']) # filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
